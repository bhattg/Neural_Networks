# Neural_Networks
This contains the implementation on numpy for standard vanilla neural networks with many functionalities including batch norm, dropout and L1 and L2 regluarisers. Available activations - Relu, Softmax, Sigmoid.


Note that the repository is not yet complete! PLEASE DO NOT FORK OR CLONE THE REPO!
